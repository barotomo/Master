{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import keras\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0228 11:55:20.788879 140736067875712 deprecation_wrapper.py:119] From /Users/Baron/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# TF-IDF→MLP\n",
    "########################################\n",
    "data=pickle.load(open('/Users/Baron/Document/text_mining/Data/pickle/TF-IDF/Headline/tfidf_headline.pickle', \"rb\"))\n",
    "z = data[0]\n",
    "y = data[1]\n",
    "x = data[2]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# 分類するラベルの数 --- (*1)\n",
    "nb_classes = 4\n",
    "MLP_model = Sequential()\n",
    "# ラベルデータをone-hotベクトルに直す --- (*3)\n",
    "y = keras.utils.np_utils.to_categorical(y, nb_classes)\n",
    "\n",
    "# データの次元数\n",
    "x_size = x[0].shape[0]\n",
    "y_size = y[0].shape[0]\n",
    "\n",
    "A_index=[]\n",
    "B_index=[]\n",
    "C_index=[]\n",
    "D_index=[]\n",
    "E_index=[]\n",
    "F_index=[]\n",
    "\n",
    "# 交差検証\n",
    "for train, test in kf.split(x):\n",
    "    A=np.empty((0,x_size), int)\n",
    "    B=np.empty((0,x_size), int)\n",
    "    C=np.empty((0,y_size), int)\n",
    "    D=np.empty((0,y_size), int)\n",
    "    E = []\n",
    "    F = []\n",
    "    for i in test:\n",
    "        A = np.append(A, [x[i]], axis=0)           # x_test\n",
    "        C = np.append(C, [y[i]], axis=0)           # y_test\n",
    "        E.append(z[i])                                          # z_test\n",
    "    A_index.append(A)\n",
    "    C_index.append(C)\n",
    "    E_index.append(E)\n",
    "    for j in train:\n",
    "        B = np.append(B, [x[j]], axis=0)            # x_train\n",
    "        D = np.append(D, [y[j]], axis=0)           # y_train\n",
    "        F.append(z[j])                                         # z_train\n",
    "    B_index.append(B)\n",
    "    D_index.append(D)\n",
    "    F_index.append(F)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_print_cmx(y_true, y_pred):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "    sn.heatmap(df_cmx, annot=True, fmt=\"d\") ### ヒートマップの表示仕様\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"predict_classes\")\n",
    "    plt.ylabel(\"true_classes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(x_test, x_train, y_test, y_train, z_test, z_train, x_size, p):\n",
    "    # MLPモデル構造を定義 --- (*5)\n",
    "    MLP_model = Sequential()\n",
    "    MLP_model.add(Dense(512, activation='relu', input_shape=(x_size,)))\n",
    "    MLP_model.add(Dropout(0.2))\n",
    "    MLP_model.add(Dense(512, activation='relu'))\n",
    "    MLP_model.add(Dropout(0.2))\n",
    "    MLP_model.add(Dense(512, activation='relu'))\n",
    "    MLP_model.add(Dropout(0.2))\n",
    "    MLP_model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    # モデルをコンパイル --- (*6)\n",
    "    MLP_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    t1 = time.time()                 #　開始\n",
    "    # 学習を実行 --- (*7)\n",
    "    hist = MLP_model.fit(x_train, y_train,\n",
    "              batch_size=128, \n",
    "              epochs=20,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    t2 = time.time()                #　終了\n",
    "    \n",
    "    # 重みデータを保存 --- (*9)\n",
    "    MLP_model.save_weights('./model/TFIDF_headline_model_'+str(p)+'.hdf5')\n",
    "    \n",
    "    #  混同行列\n",
    "    predict_classes = MLP_model.predict_classes(x_test[1:10000]) ### 予測したラベルを取得\n",
    "    true_classes = np.argmax(y_test[1:10000], 1) ### 実際のラベルを取得\n",
    "    \n",
    "    # 評価する ---(*8)\n",
    "    score = MLP_model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('\\n')\n",
    "    print(\"正解率=\", score[1], 'loss=', score[0])\n",
    "    \n",
    "    #  適応率, 再現率, F値\n",
    "    rep = metrics.classification_report(true_classes, predict_classes)\n",
    "    print(rep)\n",
    "\n",
    "    # 学習の様子をグラフへ描画 --- (*10)\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(20, 5)) # figureの縦横の大きさ\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.plot(hist.history['val_acc'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid()\n",
    "    \n",
    "    MLP_print_cmx(true_classes, predict_classes)\n",
    "    \n",
    "    # 経過時間を表示\n",
    "    elapsed_time = t2-t1\n",
    "    print(f\"処理時間：{elapsed_time}\"+\"[s]\")\n",
    "    \n",
    "    LABELS = [\"スポーツ\", \"IT\", \"映画\", \"ライフ\"]\n",
    "    A=[]\n",
    "    B=[]\n",
    "    C=[]\n",
    "    D=[]\n",
    "    for i, j, k in zip(x_test, y_test, z_test):\n",
    "        pre = MLP_model.predict(np.array([i]))[0]\n",
    "        n = pre.argmax()\n",
    "        l=np.where(j==1.0)\n",
    "        if LABELS[n]!=LABELS[l[0][0]]:\n",
    "            A.append(LABELS[n])\n",
    "            B.append(pre[n])\n",
    "            C.append(LABELS[l[0][0]])\n",
    "            D.append(k)\n",
    "\n",
    "    df=pd.DataFrame({'text':D,\n",
    "                                     'true_label':C, \n",
    "                                    'pre_label':A,\n",
    "                                    'prediction':B}\n",
    "                                   )\n",
    "    \n",
    "#     df.to_excel('Excel/TF-IDF_MLP_'+str(p)+'.xlsx', encoding='UTF-16')\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(A_index[0], B_index[0], C_index[0], D_index[0], E_index[0], F_index[0], x_size, p=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(A_index[1], B_index[1], C_index[1], D_index[1], E_index[1], F_index[1], x_size, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(A_index[2], B_index[2], C_index[2], D_index[2], E_index[2], F_index[2], x_size, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(A_index[3], B_index[3], C_index[3], D_index[3], E_index[3], F_index[3], x_size, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(A_index[4], B_index[4], C_index[4], D_index[4], E_index[4], F_index[4], x_size, p=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
