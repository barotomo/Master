{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import keras\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#  混同行列 \n",
    "########################################\n",
    "def RF_print_cmx(y_true, y_pred):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "    sn.heatmap(df_cmx, annot=True, fmt=\"d\") ### ヒートマップの表示仕様\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"predict_classes\")\n",
    "    plt.ylabel(\"true_classes\")\n",
    "    print('スポーツ : 0 / IT : 1 / 映画 : 2 / ライフ : 3')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# ランダムフォレスト \n",
    "########################################\n",
    "# データベースの読込 --- (*2)\n",
    "data=pickle.load(open('/Users/Baron/Document/text_mining/Data/pickle/TF-IDF/Body/tfidf_body.pickle', \"rb\"))\n",
    "z = data[0]\n",
    "y = data[1]\n",
    "x = data[2]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "A_index = []\n",
    "B_index = []\n",
    "C_index = []\n",
    "D_index = []\n",
    "E_index = []\n",
    "F_index = []\n",
    "pred_index = []\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    A = []\n",
    "    B = []\n",
    "    C = []\n",
    "    D = []\n",
    "    E = []\n",
    "    F = []\n",
    "    for i in test:\n",
    "        A.append(x[i])       # x_test\n",
    "        C.append(y[i])       # y_test\n",
    "        E.append(z[i])       # z_test\n",
    "    A_index.append(A)\n",
    "    C_index.append(C)\n",
    "    E_index.append(E)\n",
    "    for j in train:\n",
    "        B.append(x[j])       # x_train\n",
    "        D.append(y[j])       # y_train\n",
    "        F.append(z[j])       # z_train\n",
    "    B_index.append(B)\n",
    "    D_index.append(D)\n",
    "    F_index.append(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(x_test, x_train, y_test, y_train, z_test, z_train):\n",
    "    RF_model = RandomForestClassifier()\n",
    "    t1 = time.time()                 #　開始\n",
    "    # 学習      \n",
    "    RF_model.fit(x_train, y_train)\n",
    "    t2 = time.time()                #　終了\n",
    "    predict = RF_model.predict(x_test)\n",
    "    pred_index.append(predict)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, predict)\n",
    "    cl_report = metrics.classification_report(y_test, predict)\n",
    "\n",
    "    print('Train score: {}'.format(RF_model.score(x_train, y_train)))\n",
    "    print(\"正解率 = \", accuracy)\n",
    "    print(\"レポート\\n\", cl_report)\n",
    "    \n",
    "    RF_print_cmx(y_test, predict)\n",
    "    \n",
    "    # 経過時間を表示\n",
    "    elapsed_time = t2-t1\n",
    "    print(f\"処理時間：{elapsed_time}\"+\"[s]\")\n",
    "    \n",
    "    LABELS = [\"スポーツ\", \"IT\", \"映画\", \"ライフ\"]\n",
    "    A=[]\n",
    "    B=[]\n",
    "    C=[]\n",
    "    for i, j, k in zip(x_test, y_test, z_test):\n",
    "        pre = RF_model.predict(np.array([i]))[0]\n",
    "        if pre!=j:\n",
    "            C.append(k)\n",
    "            B.append(LABELS[j])\n",
    "            A.append(LABELS[pre])\n",
    "\n",
    "    df=pd.DataFrame({'text':C,\n",
    "                                     'true_label':B, \n",
    "                                    'pre_label':A})\n",
    "#     # df.to_excel('Excel/TF-IDF_MLP.xlsx', encoding='UTF-16')\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RF(A_index[0], B_index[0], C_index[0], D_index[0], E_index[0], F_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RF(A_index[1], B_index[1], C_index[1], D_index[1], E_index[1], F_index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RF(A_index[2], B_index[2], C_index[2], D_index[1], E_index[2], F_index[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF(A_index[3], B_index[3], C_index[3], D_index[3], E_index[3], F_index[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF(A_index[4], B_index[4], C_index[4], D_index[4], E_index[4], F_index[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
